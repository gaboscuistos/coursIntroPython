{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatisation des tâches d'administration système"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M3206 - TP 2 : Analyse de trace de connexion sur un serveur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ceci est un canevas pour votre compte-rendu de TP, que vous devrez rendre sur [e-campus](http://e-campus.iut-velizy.uvsq.fr/). Vous modifierez directement dans ce document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binôme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Nom1 Prénom1\n",
    "* Nom2 Prénom2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préambule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le fichier de logs est un exemple tiré du fichier `/var/log/messages` généré par `syslogd`, le démon de gestion de log de GNU/Linux.\n",
    "\n",
    "Les fichiers pour ce TP sont disponible sur e-campus, il s'agit de `test_messages100` et `test_messages5000`. Vérifiez le répertoire dans lequel est exécuté ce notebook et copiez-y ces deux fichiers. Comme le fichier `/var/log/messages` peut être de grande taille (> 10 Mo), nous travaillerons sur des fichiers plus petits, de 100 et 5000 lignes.\n",
    "\n",
    "Pour ce TP, vous aurez besoin d'installer les bibliothèques suivantes : \n",
    "* pyparsing\n",
    "* pandas\n",
    "* basemap (facultatif)\n",
    "\n",
    "Pour installer ces bibliothèques, si vous utilisez Anaconda, exécutez la ligne suivante:\n",
    "\n",
    "    conda install pyparsing pandas basemap\n",
    "    \n",
    "Si vous utilisez le Python de CentOS 7, exécutez les lignes:\n",
    "\n",
    "    yum install python-pip ipython\n",
    "    pip install notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme vous aller créer des figures, nous allons demander à les afficher dans le corps du notebook :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parseur de logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour lire et interpréter (*to parse* en anglais) correctement le fichier de logs, on va utiliser un *parser*. Comme il n'y pas de *parser* déjà disponible pour le fichier `/var/log/messages`, il faut l'écrire. Nous allons utiliser le module `pyparsing` qui permet de définir son propre parser.\n",
    "\n",
    "Nous allons créer une nouvelle classe de parseur que nous appellerons `SyslogParser`. Nous aurons alors besoin de définir la fonction d'initialisation, appellée quand on crée le parseur et la fonction pour parser un fichier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyparsing import Word, nums, alphas, string, Combine, Optional, Suppress, Regex, ParseException\n",
    " \n",
    "class SyslogParser(object):\n",
    "    \"\"\"Parser for syslog information\"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Parser for syslog information\n",
    "        \n",
    "        Initialize the parser for a file like /var/log/message, with lines of the form:\n",
    "        timestamp hostname command[pid]: message\n",
    "        \"\"\"\n",
    "        ints = Word(nums)\n",
    "        # extract timestamp\n",
    "        month = Word(string.ascii_uppercase, string.ascii_lowercase, exact=3)\n",
    "        day = ints\n",
    "        hour = Combine(ints + \":\" + ints + \":\" + ints)\n",
    "        timestamp = month + day + hour\n",
    "        # hostname\n",
    "        hostname = Word(alphas + nums + \"_\" + \"-\" + \".\")\n",
    "        # appname\n",
    "        command = Word(alphas + \"/\" + \"-\" + \"_\" + \".\") + Optional(Suppress(\"[\") + ints + Suppress(\"]\")) + Suppress(\":\")\n",
    "        # message\n",
    "        message = Regex(\".*\")\n",
    "        # pattern build\n",
    "        self.__pattern = timestamp + hostname + command + message\n",
    "\n",
    "    def parse(self, line):\n",
    "        \"\"\"Parser for syslog information\n",
    "        \n",
    "        Parse file like /var/log/message, with lines of the form:\n",
    "        timestamp hostname command[pid]: message\n",
    "        \"\"\"\n",
    "        payload = {}\n",
    "        try:\n",
    "            parsed = self.__pattern.parseString(line)\n",
    "            payload[\"timestamp\"] = parsed[0]+\" \"+parsed[1]+\" \"+parsed[2]\n",
    "            payload[\"hostname\"] = parsed[3]\n",
    "            payload[\"command\"] = parsed[4]\n",
    "            payload[\"pid\"] = parsed[5]\n",
    "            payload[\"message\"] = parsed[6]\n",
    "        except ParseException:\n",
    "            print (\"error parsing line:\", line)\n",
    "            pass\n",
    "        except:\n",
    "            raise\n",
    "        return payload\n",
    "    \n",
    "    def parseSSH(self, line):\n",
    "        \"\"\"Parser syslog for sshd information\n",
    "        \n",
    "        Parse files like /var/log/message, with lines of the form:\n",
    "        timestamp hostname command[pid]: message\n",
    "        Only the information relevant to sshd are kept.\n",
    "        \"\"\"\n",
    "        payload = {}\n",
    "        try:\n",
    "            parsed = self.__pattern.parseString(line)\n",
    "            if parsed[4] != 'sshd':\n",
    "                return\n",
    "            payload[\"timestamp\"] = parsed[0]+\" \"+parsed[1]+\" \"+parsed[2]\n",
    "            payload[\"pid\"] = parsed[5]\n",
    "            message = parsed[6].split(';')\n",
    "            msg = []\n",
    "            for f in message:\n",
    "                msg.append(f.split(':'))\n",
    "            if len(msg) == 1 or len(msg) == 2:\n",
    "                if message[0].split()[0] == 'reverse':\n",
    "                    payload['reversedMapping'] = False\n",
    "                    return payload\n",
    "                else:\n",
    "                    return \n",
    "            if msg[1][1] == ' Version':\n",
    "                payload[\"client\"] = msg[4][1]\n",
    "            if msg[1][1] == ' Authname':\n",
    "                payload[\"user\"] = msg[3][1].split('[')[0]\n",
    "            payload['ip'] = msg[2][1]\n",
    "        except ParseException:\n",
    "            print (\"error parsing line:\", line)\n",
    "            pass\n",
    "        except:\n",
    "            print (\"error parsing line:\", line)\n",
    "            raise\n",
    "        return payload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir importé les modules et fonctions dont nous avions besoin, nous avons crée la classe `SyslogParser` et nous lui avons associé deux fonctions `__init__(self)` (qui est obligatoire) et `parse(self, line)` qui nous permet de parser la ligne `line` passée en argument. \n",
    "\n",
    "La fonction `__init__(self)` utilise les outils fournis par le module `pyparsing` pour définir un patron (ou *pattern* en anglais) de ligne qui est appelé `__pattern`. Celui ci est de la forme : `timestamp hostname command[pid]: message` et utilise les fonctions de pyparsing pour une robustesse maximale. On définit ensuite la fonction `parse(self, line)` qui sert à parser une ligne. La ligne est donnée au parseur de patron `__pattern` qui retourne une liste appelée `parsed`. Cette liste est utilisée pour créer un dictionnaire nommé `payload` (qu'on peut traduire par *message utile* en français). Ce dictionnaire à 5 champs (ou `keys`):\n",
    "\n",
    "* `timestamp` : la date\n",
    "* `hostname` : le nom de la machine\n",
    "* `command` : le nom de l'application qui écrit dans le fichier de logs\n",
    "* `pid` : le PID de l'application (son numéro de processus)\n",
    "* `message` : le message que l'application à envoyé\n",
    "\n",
    "La fonction `parseSSH(self, line)` permet de traiter uniquement les lignes générées par le démon `sshd` et de les analyser plus finement. Cette fonction parse la ligne `line` donnée en paramètre et retourne le dictionnaire `payload` qui contient suivant (ceux qui sont facultatifs sont indiqués) :\n",
    "\n",
    "* `timestamp` : la date\n",
    "* `pid` : le PID de l'application\n",
    "* `client` : le nom et la version du client ssh (facultatif)\n",
    "* `user` : le nom de l'utilisateur utilisé (facultatif)\n",
    "* `reversedMapping` : vérification du *reverse mapping* (pour éviter les tentatives d'IP spoofing)\n",
    "\n",
    "Nous allons vérifier si notre parseur fonctionne avec un exemple simple, une ligne tirée du fichier `messages`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_line = \"Nov 28 03:50:01 bach cron[16620]: (root) CMD (test -x /usr/sbin/run-crons && /usr/sbin/run-crons)\"\n",
    "parser = SyslogParser()\n",
    "fields = parser.parse(sample_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez la ligne à traiter et la ligne traitée pour vérifier si le code à bien fonctionné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nov 28 03:50:01 bach cron[16620]: (root) CMD (test -x /usr/sbin/run-crons && /usr/sbin/run-crons)\n",
      "{'timestamp': 'Nov 28 03:50:01', 'pid': '16620', 'hostname': 'bach', 'command': 'cron', 'message': '(root) CMD (test -x /usr/sbin/run-crons && /usr/sbin/run-crons)'}\n",
      "Le Nov 28 03:50:01 le programme cron a ecrit :  (root) CMD (test -x /usr/sbin/run-crons && /usr/sbin/run-crons)\n"
     ]
    }
   ],
   "source": [
    "print (sample_line)\n",
    "print (fields)\n",
    "\n",
    "print (\"Le\", fields['timestamp'], \n",
    "       \"le programme\", fields['command'], \n",
    "       \"a ecrit : \", fields['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir vérifié que notre parseur a bien fonctionné, et que tous les champs sont bien renseignés. La ligne parsée génère un dictionnaire, appellé `fields` ici, dont les entrées sont les différents champs.\n",
    "\n",
    "Avant de traiter le vrai fichier `/var/log/messages`, nous allons utiliser un fichier de test, qui contient les premières lignes de `/var/log/messages`. Cela nous permettra de faire une première analyse, de vérifier le bon fonctionnement sans avoir besoin de traiter l'intégralité des données du vrai fichier. Une fois les tests réalisés, nous pourrons traiter l'intégralité du fichier `message`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Écrivez le code qui permet d'ouvrir le fichier `test_messages5000` et qui parse chacune de ses lignes. Les lignes ainsi parsées  sont à aggréger dans une liste que vous appelerez `log_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifiez la taille de `log_list`, qui doit être égale à 5000 si vous avez ouvert `test_messages5000`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a bien un nombre de lignes relativement faible pour le fichier de test, comparativement aux 200 000 lignes du \"vrai\" fichier `/var/log/messages`.\n",
    "\n",
    "Nous allons maintenant utiliser le module `pandas` pour mettre en forme les données. Ce module permet de créer des *DataFrames* : ce sont des conteneurs qui permettent de mettre l'information en forme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame, Panel\n",
    "df = DataFrame(log_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichez les 3 premières éléments de `df`. Les *DataFrame* peuvent se manipuler comme des listes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant utiliser le champ `timestamp` comme étiquettes temporelles pour nos logs :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df.index = pd.to_datetime(df.pop(df['timestamp'])) ne fonctionne pas avec pandas 1.7\n",
    "from datetime import datetime\n",
    "\n",
    "ts = []\n",
    "for s in df.timestamp:\n",
    "    ts.append(datetime.strptime(\"2014 \"+s, \"%Y %b %d %H:%M:%S\"))\n",
    "df.index = pd.to_datetime(ts)\n",
    "del df['timestamp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est possible d'afficher les informations sur cette *DataFrame* avec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est également possible d'afficher les informations sur le contenus et les différents champs de la *DataFrame* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons maintenant quels sont les applications qui ont envoyées des messages, nous allons utiliser la fonction `value_counts` pour afficher l'ensemble des valeurs prises par le champs `command`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.command.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelle est la commande la plus fréquente ? Que pouvez vous dire sur les tâches de `cron` ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures et visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut générer un histogramme à partir de ces données de la façon suivante. On regroupe les informations de la *DataFrame* par commande. On calcule ensuite le nombre de chaque commande avec la fonction `size()` puis on affiche un diagramme en bâtons (*bars* en anglais). La bibliothèque Pandas permet de générer facilement toute sort de graphique en appelant la fonction `plot()` avec comme argument `kind`. Les types possibles sont: \n",
    "\n",
    "* `bar` ou `barh` pour les diagrammes (verticaux ou horizontaux)\n",
    "* `hist` pour les histogrammes\n",
    "* `box` pour les boîtes à moustaches\n",
    "* `kde` ou `density` pour les figures de densité de probabilités\n",
    "* `area` pour les aires \n",
    "* `scatter` pour les nuages de points\n",
    "* `hexbin` pour les cartes hexagonales\n",
    "* `pie` pour les camemberts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped_status = df.groupby('command')\n",
    "grouped_status.size().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons maintenant le nombres de messages générés toutes les dix minutes. On va donc ré-échantilloner les commandes avec `resample()` en faisant des paquets de 10 minutes (indiqué ici par `10t`) dans lesquels on va sommer chaque commande (avec `how='count'`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_s = df.command.resample('10t', how='count')\n",
    "df_s.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour voir la part respectives de chaque applications dans la génération de log, on peut séparer les données quantitative pour chaque application puis les regrouper dans un *DataFrame* commun. On peut en profiter pour regrouper les activités de `cron` de `run-crons` sous la même étiquette. Pour avoir des résultats interprétables, on aggrège les messages par groupe de 2h (`120t`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_span = '120t'\n",
    "df_cron = df['command'][df['command'].isin(['cron', 'run-crons']) ].resample(t_span, how='count')\n",
    "df_sshd = df['command'][df['command'] == 'sshd'].resample(t_span, how='count')\n",
    "df_syslog = df['command'][df['command'] == 'syslog-ng'].resample(t_span, how='count')\n",
    "\n",
    "status_df = DataFrame({'cron': df_cron, \n",
    "                       'sshd': df_sshd, \n",
    "                       'syslog': df_syslog})\n",
    "status_df.plot(kind=\"bar\", stacked=True, color=(\"r\", \"g\",\"b\"), xticks=())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des traces SSH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici un exemple de traces SSH : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples=[\n",
    "\"Nov 28 05:01:44 bach sshd[17038]: SSH: Server;Ltype: Version;Remote: 122.225.97.104-29185;Protocol: 2.0;Client: libssh2_1.4.2\", \n",
    "\"Nov 28 05:01:45 bach sshd[17038]: SSH: Server;Ltype: Kex;Remote: 122.225.97.104-29185;Enc: aes128-ctr;MAC: hmac-sha1;Comp: none [preauth]\",\n",
    "\"Nov 28 05:01:59 bach sshd[17038]: SSH: Server;Ltype: Authname;Remote: 122.225.97.104-29185;Name: root [preauth]\",\n",
    "\"Nov 28 05:01:59 bach sshd[17038]: reverse mapping checking getaddrinfo for mx7.fund123.cn [122.225.97.104] failed - POSSIBLE BREAK-IN ATTEMPT!\",\n",
    "\"Nov 28 05:01:59 bach sshd[17038]: User root from 122.225.97.104 not allowed because not listed in AllowUsers\",\n",
    "\"Nov 28 05:01:59 bach sshd[17038]: input_userauth_request: invalid user root [preauth]\",\n",
    "\"Nov 28 05:01:59 bach sshd[17038]: Connection closed by 122.225.97.104 [preauth]\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir que les informations sur la connexion SSH sont réparties sur plusieurs messages :\n",
    "\n",
    "* Le premier indique l'adresse IP, la version du protocole, le client. \n",
    "* Le second précise l'encryptage et les moyens cryptographiques. \n",
    "* Le troisième donne l'utilisateur utilisé pour la connexion.\n",
    "* Le quatrième indique que le nom de la machine ne correspond pas à l'adresse IP.\n",
    "* Le cinquième explique que `root` n'est pas admis à se connecter en SSH.\n",
    "* Le sixième indique le message envoyé au client.\n",
    "* Le septième précise que la connexion a été fermée par le client.\n",
    "\n",
    "Ces sept message sont issus du même processus, on peut voir que le PID est le même pour tous. Or le parseur SSH permet seulement d'analyser les logs lignes à lignes. Le résultat est le suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parser = SyslogParser()\n",
    "for s in samples:\n",
    "    print (\"Ligne parsée :\\n\", parser.parseSSH(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le parseur retourne des informations différentes pour les 4 premières lignes et ne retourne rien pour les 3 dernières."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Écrivez le code nécessaire pour traiter le fichier `test_message100` et :\n",
    "\n",
    "* Créer une liste appelée `sshlog_list` qui va stocker toutes les lignes parsées\n",
    "* Supprimer les élements vide de la liste (leur valeur est `None`)\n",
    "* Traiter les éléments de la liste pour fusionner ceux qui ont le même PID. Vous utiliserez `a.update(b)` qui permet de mettre à jour les champs de `a` avec ceux de `b` et `del b` qui permet du supprimer `b`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir validé votre code sur la question précédente, adaptez le pour traiter le fichier `test_messages5000`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertissons maintenant la liste obtenue sur ce fichier en *DataFrame* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = DataFrame(sshlog_list)\n",
    "ts = []\n",
    "for s in df.timestamp:\n",
    "    ts.append(datetime.strptime(\"2014 \"+s, \"%Y %b %d %H:%M:%S\"))\n",
    "df.index = pd.to_datetime(ts)\n",
    "del df['timestamp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez utiliser `df.info()` et `df.describe()` pour vérifier les informations sur la *DataFrame*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisez la fonction `plot()` pour mettre sous forme de figures les informations de votre fichier de message. Vous proposerez une petite analyse des informations ainsi obtenues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question (*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette question est facultative. Vous utiliserez le module Basemap pour afficher une carte sur monde sur laquelle vous afficherez les positions géographiques associées à ces adresses IP. Pour cela, vous utiliserez le code suivant qui permet de récuperer les coordonnées de latitude et de longitude pour chaque IP. Le site freegeoip.net qui propose ce service limite le nombre de demandes. Vous devrez donc d'abord enlever les doublons, c'est à dire éviter de faire plusieurs requêtes pour la même IP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from csv import reader\n",
    "from urllib.request import urlopen # drop request for python 2 version\n",
    "from codecs import iterdecode\n",
    "FREE_GEOIP_CSV_URL = \"http://freegeoip.net/csv/%s\"\n",
    "def valid_ip(ip):\n",
    "\n",
    "    pattern = r\"\\b(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\b\"\n",
    "\n",
    "    return re.match(pattern, ip)\n",
    "\n",
    "def __get_geodata_csv(ip):\n",
    "    if not valid_ip(ip):\n",
    "        raise Exception('Invalid IP format', 'You must enter a valid ip format: X.X.X.X')\n",
    "\n",
    "    URL = FREE_GEOIP_CSV_URL % ip\n",
    "    httpstream = urlopen(URL)\n",
    "    response_csv = reader(iterdecode(httpstream, 'utf-8'))\n",
    "#    response_csv = reader(urlopen(URL))\n",
    "    csv_data = next(response_csv)    \n",
    "\n",
    "    return {\n",
    "        \"status\": u\"True\" == csv_data[0],\n",
    "        \"ip\":csv_data[1],\n",
    "        \"countrycode\":csv_data[2],\n",
    "        \"countryname\":csv_data[3],\n",
    "        \"regioncode\":csv_data[4],\n",
    "        \"regionname\":csv_data[5],\n",
    "        \"city\":csv_data[6],\n",
    "        \"zipcode\":csv_data[7],\n",
    "        \"latitude\":csv_data[8],\n",
    "        \"longitude\":csv_data[9]\n",
    "    }\n",
    "\n",
    "def get_geodata(ip):\n",
    "    return __get_geodata_csv(ip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Écrivez le code qui permette de récupérer `lats`, la liste des latitudes,\n",
    "et `lons`, la liste des longitudes, associées aux IP uniques:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "from matplotlib.pyplot import figure\n",
    "from numpy import log\n",
    "\n",
    "m = Basemap(projection='mill') # creation de la carte en utilisant la projection de Millner\n",
    "figure(figsize=(12,16)) # on change la taille de la figure\n",
    "x, y = m(lons, lats) # lons et lats sont les listes des latitudes et des longitudes des IP\n",
    "m.scatter(x, y, s=10*log(ipnb**10), marker='o', color='r') # on affiche des points au coordonnées des IP\n",
    "m.drawcoastlines(color='SaddleBrown') # on affiche les côtes\n",
    "m.drawmapboundary(fill_color='SkyBlue') # on remplit les océans\n",
    "_ = m.fillcontinents(color='BurlyWood',lake_color='SkyBlue', zorder=0) # on remplit les continents"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
